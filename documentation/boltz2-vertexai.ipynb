{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef34eeef",
   "metadata": {},
   "source": [
    "# Boltz on Vertex AI \n",
    "\n",
    "---\n",
    "\n",
    "This guide walks you through **deploying Botlz‑2** to Google Cloud’s Vertex AI. We’ll cover:\n",
    "\n",
    "1. **Quick introduction to Botlz‑2** and its scientific background  \n",
    "2. **Local setup** using Docker  \n",
    "3. **Pushing the Docker image** to Google’s Artifact Registry  \n",
    "4. **Spinning up and using** the container locally  \n",
    "5. **Submitting a Vertex AI job** for scalable cloud execution\n",
    "\n",
    "Check out the [Boltz-2 notebook](./boltz2.ipynb) for interactive examples.\n",
    "\n",
    "## Introduction to Botlz-2's Protein-Folding Journey and Cloud Compute\n",
    "\n",
    "---\n",
    "\n",
    "Predicting 3D protein structures has been a “grand challenge” since Anfinsen’s classic folding experiments in the 1970s [1]. Major landmarks like CASP (1994) [2], Rosetta (2000s) [3,4,5], AlphaFold 2 (2020) [6,7], and RoseTTAFold (2021) [8] have shaped the field. Botlz‑2 joins this lineage, offering faster, high-quality predictions with a lightweight Boltzmann‑inspired architecture.\n",
    "\n",
    "By deploying Botlz‑2 on Vertex AI:\n",
    "- **Reproducible local development** via Docker  \n",
    "- **Scalable training & inference** on managed cloud infrastructure  \n",
    "- **Smooth integration** into protein-folding pipelines  \n",
    "\n",
    "Whether you're an academic or industry researcher, this setup makes Botlz‑2 production-ready in the post-AlphaFold era.\n",
    "\n",
    "\n",
    "## Notebook Roadmap\n",
    "\n",
    "---\n",
    "\n",
    "### Sections\n",
    "- [Building and Pushing Boltz2 Docker Image to GCP Artifact Registry](#pushing-boltz2-image-to-gcp-artifact-regsitry)\n",
    "- [Building and Running GCP Docker Container](#building-and-running-the-docker-container)\n",
    "- [Submitting Job to Vertex AI](#submit-custom-job-to-vertex-ai)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before you begin, ensure you have the following installed on your local machine:\n",
    "\n",
    "- Docker: [Install Docker](https://docs.docker.com/get-docker/)\n",
    "- GCP Credentidals: Select appropriate [autheticaction for your use case](https://cloud.google.com/docs/authentication#auth-decision-tree). We will use a secure approach of [authentication with user credentials](https://cloud.google.com/docs/authentication/set-up-adc-local-dev-environment#local-user-cred). Make sure your user has role `Vertex AI User` assigned to grant access to Vertex AI resource.\n",
    "\n",
    "Please reference the documentation on [setting up you environment](./local-env.md) for more information and tips.\n",
    "\n",
    "\n",
    "## Pushing Boltz2 Docker Image to GCP Artifact Registry\n",
    "\n",
    "---\n",
    "\n",
    "To build a GCP compatible Boltz2 docker image, follow these steps:\n",
    "\n",
    "1. **Clone the Repository**: Clone the `MLContainerLab` repository to your local machine.\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/gabenavarro/MLContainerLab.git\n",
    "cd MLContainerLab\n",
    "```\n",
    "\n",
    "2. **Build the Docker Image**: Use the provided Dockerfile to build the Docker image.\n",
    "\n",
    "```bash\n",
    "docker build -f ./assets/build/Dockerfile.boltz2.cu126cp310 -t boltz2:126-310 .\n",
    "```\n",
    "\n",
    "3. **Tag the Docker Image**: Add a GCP Artifact registry tag to the image\n",
    "\n",
    "```bash\n",
    "docker tag boltz2:126-310 ${DEFAULT-ARTIFACT-REGISTRY}/${PROJECT-ID}/${REPOSITORY-NAME}/boltz2:126-310\n",
    "```\n",
    "\n",
    "Replace `${DEFAULT-ARTIFACT-REGISTRY}` with your default region. For example, if using `us-west1-docker.pkg.dev`:\n",
    "\n",
    "* `docker tag boltz2:126-310 us-west1-docker.pkg.dev/my-project/my-repository/boltz2:126-310`\n",
    "\n",
    "4. **Push to Registry**:\n",
    "\n",
    "```bash\n",
    "docker push ${DEFAULT-ARTIFACT-REGISTRY}/${PROJECT-ID}/${REPOSITORY-NAME}/boltz2:126-310\n",
    "```\n",
    "\n",
    "Make sure you have given access to Docker to push images to artifact regsitry. For more information reference the documentation on [setting up you environment](./local-env.md).\n",
    "\n",
    "\n",
    "## Building and Running the GCP Docker Container\n",
    "\n",
    "---\n",
    "\n",
    "The next image to build will allow you to send jobs to Google Veretx AI. To simplify this for most computational scientist, this will be and interactive detached container that you can connect to using VSCode (or your favorite IDE). Lets start with the steps below:\n",
    "\n",
    "1. **Clone the Repository**: Clone the `MLContainerLab` repository to your local machine if you havent already.\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/gabenavarro/MLContainerLab.git\n",
    "cd MLContainerLab\n",
    "```\n",
    "\n",
    "2. **Build the Docker Image**: Use the provided Dockerfile to build the Docker image.\n",
    "\n",
    "```bash\n",
    "docker build -f ./assets/build/Dockerfile.gcpvertexiai.cp312 -t vertexai:312 .\n",
    "```\n",
    "\n",
    "3. **Run the Docker Container**: Run the Docker container with the necessary configurations. In the first example, we will run the container locally with GPU support. This is the recommended way to run a container while in development mode. For scaling up, we will use the second example which runs the container in the cloud.\n",
    "\n",
    "```bash\n",
    "# Run the container with GPU support\n",
    "docker run -dt \\\n",
    "   -v \"$(pwd):/workspace\" \\\n",
    "   --name vertexai \\\n",
    "   vertexai:313\n",
    "```\n",
    "> Note: The `-v \"$(pwd):/workspace\"` option mounts the current directory to `/workspace` in the container, allowing you to access your local files from within the container. The `--env` options set environment variables for GPU visibility and Google Cloud credentials.<br>\n",
    "\n",
    "4. **Access the Container with IDE**: In this example, we will use Visual Studio Code to access the container. You can use any IDE of your choice.\n",
    "\n",
    "```bash\n",
    "# In a scriptable manner\n",
    "CONTAINER_NAME=vertexai\n",
    "FOLDER=/workspace\n",
    "HEX_CONFIG=$(printf {\\\"containerName\\\":\\\"/$CONTAINER_NAME\\\"} | od -A n -t x1 | tr -d '[\\n\\t ]')\n",
    "code --folder-uri \"vscode-remote://attached-container+$HEX_CONFIG$FOLDER\"\n",
    "```\n",
    "\n",
    "\n",
    "[1]: https://aklectures.com/lecture/structure-of-proteins/anfinsens-experiment-of-protein-folding \"Anfinsen's Experiment of Protein Folding - AK Lectures\"\n",
    "[2]: https://en.wikipedia.org/wiki/CASP \"CASP - Wikipedia\"\n",
    "[3]: https://docs.rosettacommons.org/docs/latest/meta/Rosetta-Timeline \"History of Rosetta\"\n",
    "[4]: https://pmc.ncbi.nlm.nih.gov/articles/PMC7603796 \"Macromolecular modeling and design in Rosetta: recent methods ...\"\n",
    "[5]: https://en.wikipedia.org/wiki/Rosetta%40home \"Rosetta@home\"\n",
    "[6]: https://www.nature.com/articles/s41586-021-03819-2 \"Highly accurate protein structure prediction with AlphaFold - Nature\"\n",
    "[7]: https://www.wired.com/story/deepmind-alphafold-protein-diseases \"DeepMind wants to use its AI to cure neglected diseases\"\n",
    "[8]: https://www.bakerlab.org/2021/07/15/accurate-protein-structure-prediction-accessible \"Accurate protein structure prediction accessible to all - Baker Lab\"\n",
    "[9]: https://www.lemonde.fr/en/science/article/2024/10/09/nobel-prize-for-chemistry-2024-artificial-intelligence-garners-more-recognition_6728828_10.html \"Nobel Prize for Chemistry 2024: Artificial intelligence garners more recognition\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb1f06",
   "metadata": {},
   "source": [
    "\n",
    "## Submitting Job to Vertex AI\n",
    "\n",
    "Now, lets go through an example of submitting the Docker container as a managed job.\n",
    "\n",
    "\n",
    "1. **Authentication**\n",
    "\n",
    "First, start by authenticating  your session using user credentials in bash. If you are using a containerized notebook using vscode, make sure to open the terminal in the container and run the following command there.\n",
    "\n",
    "```bash\n",
    "# Authenticate credentials\n",
    "gcloud auth login\n",
    "# Setup configuration\n",
    "# Most likely you will want to use option 1 when prompted\n",
    "gcloud init \n",
    "# Lastly setup ADC authetication\n",
    "gcloud auth application-default login \n",
    "```\n",
    "\n",
    "2.  **Build Files**\n",
    "\n",
    "First, initialize function below in order to read in file with molecules that you'd like to bind to an input protein of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify to fit your project\n",
    "PROJECT = \"YOUR-PROJECT-NAME\"\n",
    "REGION = \"YOUR-REGION\"\n",
    "ARTIFACT_PROJECT = \"ARTIFACT-REGISTRY-PROJECT\"\n",
    "REGISTRY_REGION = \"YOUR-ARTIFACT-REGION\"\n",
    "BUCKET = \"YOUR-BUCKET-NAME\"\n",
    "MACHINE_TYPE = \"\"\n",
    "ACCELERATOR_TYPE = \"\"\n",
    "IMAGE = f\"{REGISTRY_REGION}/{PROJECT}/${ARTIFACT_PROJECT}/boltz2:126-310\"\n",
    "VALID_AMINO_ACIDS = set(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "FLEX_START_MACHINES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95104696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from networkx import project\n",
    "from pandas import read_csv\n",
    "from rdkit import Chem\n",
    "from datetime import datetime\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform_v1.types import custom_job as gca_custom_job_compat\n",
    "import subprocess\n",
    "import hashlib\n",
    "from time import sleep\n",
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "def check_gcs_file_exists(bucket_name:str, blob_name:str):\n",
    "    \"\"\"Checks if a file exists in a GCS bucket.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the GCS bucket.\n",
    "        file_name (str): The name of the file (object) within the bucket.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file exists, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob_exists = blob.exists()\n",
    "    except:\n",
    "        blob_exists = False\n",
    "    finally:\n",
    "        storage_client.close()\n",
    "    \n",
    "    return blob_exists\n",
    "\n",
    "\n",
    "def molecules_for_boltz_from_file(\n",
    "    filename: str\n",
    ") -> List[str]:\n",
    "    '''Molecules\n",
    "    ---\n",
    "\n",
    "    Creates an interator to return each molecule from a given input. Can accept\n",
    "        * `.csv` : files with `smiles` columns. \n",
    "        * `.sdf`\n",
    "    \n",
    "    ### Arg\n",
    "        * filename (str): path to file with encoded molecules.\n",
    "        \n",
    "    ### Return\n",
    "        * smiles (list): list of molecules in smiles format, required for Boltz-2.\n",
    "    '''\n",
    "    # Make sure its correct file type\n",
    "    assert filename.endswith(\".csv\") or filename.endswith(\".sdf\"), \"Not .csv or .sdf file\"\n",
    "    if filename.endswith(\".sdf\"):\n",
    "        try:\n",
    "            smiles = [Chem.MolToSmiles(i) for i in Chem.SDMolSupplier(filename)]\n",
    "        except:\n",
    "            ValueError( f\"Error opening `.sdf` file: {filename}\")\n",
    "    # If csv, make sure it has `smiles columns`\n",
    "    if filename.endswith(\".csv\"):\n",
    "        df = read_csv(filename)\n",
    "        df.columns = [i.upper() for i in df.columns]\n",
    "        assert any([i == \"SMILES\" for i in df.columns]), \"No SMILES column found in csv\"\n",
    "        smiles = df[\"SMILES\"].to_list()\n",
    "    return smiles\n",
    "\n",
    "\n",
    "def build_yaml_file(\n",
    "    molecules: List[str],\n",
    "    protein: str,\n",
    "    experiment_name: str | None = None,\n",
    "    cache: str = \"../datasets/botlz2-yaml\"\n",
    ") -> List[str]:\n",
    "    \n",
    "    # Simple handling\n",
    "    assert molecules, \"No molecules provided\"\n",
    "    assert protein and protein.isupper() and not (set(protein) - VALID_AMINO_ACIDS), \\\n",
    "    \"Protein sequence must not be empty, be all uppercase, and contain only standard amino acid characters.\"\n",
    "    experiment_name = experiment_name if experiment_name is not None else datetime.today().strftime(\"%d-%m-%Y--%H-%M-%S\")\n",
    "    os.makedirs(cache, exist_ok=True)\n",
    "    os.makedirs(f\"{cache}/{experiment_name}\", exist_ok=True)\n",
    "\n",
    "    # Write file\n",
    "    yaml_jobs = []\n",
    "    for mol in molecules:\n",
    "        yaml_str = f\"\"\"# This is a comment\n",
    "    version: 1\n",
    "    sequences:\n",
    "        - protein:\n",
    "            id: A \n",
    "            sequence: {protein.upper()}\n",
    "        - ligand:\n",
    "            id: B\n",
    "            smiles: '{mol}'\n",
    "    properties:\n",
    "        - affinity:\n",
    "            binder: B\n",
    "    \"\"\"\n",
    "        hash_name = hashlib.sha256(mol.encode('utf-8')).hexdigest()\n",
    "        with open(f\"{cache}/{experiment_name}/{hash_name}.yaml\", \"w\") as f:\n",
    "            f.write(yaml_str)\n",
    "            yaml_jobs.append(f\"/gcs/{BUCKET}/bolts2/jobs/{experiment_name}/{hash_name}.yaml\")\n",
    "\n",
    "    # Move them to GCP, will only work if authenticated\n",
    "    cmd = f\"gsutil -m cp -r {cache}/{experiment_name} gs://{BUCKET}/boltz2/jobs\"\n",
    "    subprocess.run(cmd,shell=True)\n",
    "    return yaml_jobs\n",
    "\n",
    "\n",
    "def build_protein_protein_yaml_file(\n",
    "    protein_a: str,\n",
    "    protein_b: str,\n",
    "    experiment_name: str | None = None,\n",
    "    cache: str = \"../datasets/botlz2-yaml\"\n",
    ") -> List[str]:\n",
    "    \n",
    "    # Simple handling\n",
    "    assert protein_a and protein_a.isupper() and not (set(protein_a) - VALID_AMINO_ACIDS), \\\n",
    "    \"Protein A sequence must not be empty, be all uppercase, and contain only standard amino acid characters.\"\n",
    "    assert protein_b and protein_b.isupper() and not (set(protein_b) - VALID_AMINO_ACIDS), \\\n",
    "    \"Protein A sequence must not be empty, be all uppercase, and contain only standard amino acid characters.\"\n",
    "    experiment_name = experiment_name if experiment_name is not None else datetime.today().strftime(\"%d-%m-%Y--%H-%M-%S\")\n",
    "    os.makedirs(cache, exist_ok=True)\n",
    "    os.makedirs(f\"{cache}/{experiment_name}\", exist_ok=True)\n",
    "\n",
    "    # Write file\n",
    "    yaml_jobs = []\n",
    "\n",
    "    yaml_str = f\"\"\"# This is a comment\n",
    "version: 1\n",
    "sequences:\n",
    "    - protein:\n",
    "        id: A \n",
    "        sequence: {protein_a.upper()}\n",
    "    - protein:\n",
    "        id: B\n",
    "        sequence: {protein_b.upper()}\n",
    "\"\"\"\n",
    "    hash_name = hashlib.sha256(str(protein_a.upper()+protein_b.upper()).encode('utf-8')).hexdigest()\n",
    "    with open(f\"{cache}/{experiment_name}/{hash_name}.yaml\", \"w\") as f:\n",
    "        f.write(yaml_str)\n",
    "        yaml_jobs.append(f\"/gcs/{BUCKET}/boltz2/jobs/{experiment_name}/{hash_name}.yaml\")\n",
    "\n",
    "    # Move them to GCP, will only work if authenticated\n",
    "    cmd = f\"gsutil -m cp -r {cache}/{experiment_name} gs://{BUCKET}/boltz2/jobs\"\n",
    "    print(cmd)\n",
    "    subprocess.run(cmd,shell=True)\n",
    "    return yaml_jobs\n",
    "\n",
    "\n",
    "def submit_vertex_custom_job(yaml_jobs: List[str]):\n",
    "\n",
    "    aiplatform.init(\n",
    "        project=PROJECT,\n",
    "        location=REGION\n",
    "    )\n",
    "\n",
    "    for job in yaml_jobs:\n",
    "        hash_name = job.split(\"/\")[-1].replace(\".yaml\",\"\").split(\"_\")[-1]\n",
    "        experiment_name = job.split('/')[-2]\n",
    "\n",
    "        if not check_gcs_file_exists(\n",
    "            BUCKET,\n",
    "            f\"boltz2/results/{experiment_name}/boltz_results_{hash_name}/predictions/{hash_name}/{hash_name}_model_0.cif\"\n",
    "        ):\n",
    "            CMD = [\n",
    "                \"boltz\",\n",
    "                \"predict\", job,\n",
    "                \"--recycling_steps\", \"10\",\n",
    "                \"--diffusion_samples\", \"25\",\n",
    "                \"--accelerator\", \"gpu\",\n",
    "                \"--out_dir\", f\"/gcs/{BUCKET}/boltz2/results/{experiment_name}\",\n",
    "                \"--cache\", f\"/gcs/{BUCKET}/boltz2/cache\",\n",
    "                \"--use_msa_server\"\n",
    "            ]\n",
    "\n",
    "            WORKER_POOL_SPECS = [\n",
    "                {\n",
    "                    \"replica_count\": 1,\n",
    "                    \"machine_spec\": {\n",
    "                        \"machine_type\": MACHINE_TYPE,\n",
    "                        \"accelerator_count\": 1,\n",
    "                        \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "                    },\n",
    "                    \"container_spec\": {\n",
    "                        \"image_uri\": IMAGE, \n",
    "                        \"command\": CMD, \n",
    "                    },\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            job = aiplatform.CustomJob(\n",
    "                display_name=f\"Boltz-2 {experiment_name}\", \n",
    "                worker_pool_specs=WORKER_POOL_SPECS,\n",
    "                staging_bucket=f\"gs://{BUCKET}/vertex_staging\",\n",
    "            )\n",
    "\n",
    "            if MACHINE_TYPE in FLEX_START_MACHINES:\n",
    "                job.submit(\n",
    "                    max_wait_duration=7200,\n",
    "                    scheduling_strategy=gca_custom_job_compat.Scheduling.Strategy.FLEX_START\n",
    "                )\n",
    "            else:\n",
    "                job.submit()\n",
    "\n",
    "            sleep(5)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9dbae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_path = \"my-mol-path\"\n",
    "molecules = molecules_for_boltz_from_file(molecule_path)\n",
    "protein = \"YOUR-AA-SEQUENCE\"\n",
    "\n",
    "vertex_jobs = build_yaml_file(\n",
    "    molecules=molecules,\n",
    "    protein=protein\n",
    ")\n",
    "\n",
    "submit_vertex_custom_job(vertex_jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
