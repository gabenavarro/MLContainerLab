{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef34eeef",
   "metadata": {},
   "source": [
    "# DrugFlow on Vertexâ€¯AI ðŸš€\n",
    "\n",
    "---\n",
    "\n",
    "This guide walks you through **deploying DrugFlow** on Google Cloudâ€™s Vertexâ€¯AI. Weâ€™ll cover:\n",
    "\n",
    "1. **Quick introduction to DrugFlow** and its scientific background  \n",
    "2. **Local setup** using Docker  \n",
    "3. **Pushing the Docker image** to Google Artifact Registry  \n",
    "4. **Spinning up and using** the container locally  \n",
    "5. **Submitting a Vertexâ€¯AI job** for scalable execution in the cloud  \n",
    "\n",
    "Check out the interactive [DrugFlow notebook](./drugflow.ipynb) for hands-on examples.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to DrugFlow & the Rise of Generative AI in Drug Discovery\n",
    "\n",
    "Drug discovery has evolved dramaticallyâ€”from the chance discovery of **penicillin** to today's data-driven molecular design. Recent advances in **generative AI** are now enabling *inverse drug design*, where models generate molecules tailored to specific protein targets.\n",
    "\n",
    "### ðŸ§¬ Key Milestones in Drug Discovery\n",
    "\n",
    "| Era             | Highlight                                              | Significance                                                                 |\n",
    "|-----------------|--------------------------------------------------------|-------------------------------------------------------------------------------|\n",
    "| 1900sâ€“1970s     | Natural product discovery (e.g., penicillin)          | Serendipitous findings shaped early pharmacology                             |\n",
    "| 1980sâ€“1990s     | Rational design via docking & crystallography          | Led to HIV-protease and ACE inhibitor drugs                                 |\n",
    "| 2000s           | High-throughput screening; QSAR                       | Enabled large-scale similarity-based screening                              |\n",
    "| 2010s           | ML enters bench (DeepChem, ChemBERTa)                 | Models began predicting molecular properties                                 |\n",
    "| 2020s           | Emergence of generative diffusion models              | From image generation (DDPM, RFdiffusion) to drug design with DrugFlow (ICLRâ€¯'25) [[1]](#refs-df) |\n",
    "\n",
    "### ðŸ”¬ Why Diffusion-Based Generative Models Matter\n",
    "\n",
    "Generative models shift drug discovery from screening to designing:\n",
    "\n",
    "- **SMILES RNNs / VAEs** â†’ early molecule creation, but often invalid or repetitive  \n",
    "- **GNN-VAEs** (e.g., JT-VAE, GraphAF) â†’ better molecular validity  \n",
    "- **Diffusion models** (e.g., DDPM, RFdiffusion [ProteinDesign][], DiffSBDD [DiffSBDDGitHub][]) â†’ scaffold-aware, pocket-conditioned generation with improved structural realism  \n",
    "\n",
    "**DrugFlow** introduces a novel *flow-matching* generative model that jointly learns molecular and protein conformation distributions, providing atom-level uncertainty estimates and enabling preference-based sampling across modalities [[1]](#refs-df).\n",
    "\n",
    "[ProteinDesign]: https://www.nature.com/articles/s41586-023-06415-8 \"Deâ€¯novo protein design with RFdiffusion (Nature 2023)\"  \n",
    "[DiffSBDDGitHub]: https://github.com/arneschneuing/DiffSBDD \"DiffSBDD: Equivariant diffusion for structure-based drug design\"  \n",
    "[#refs-df]: https://openreview.net/forum?id=g3VCIM94ke \"Multi-domain Distribution Learning for De Novo Drug Design (DrugFlow, ICLR 2025)\"  \n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Roadmap\n",
    "\n",
    "---\n",
    "\n",
    "### Sections\n",
    "\n",
    "- [Building & Pushing the Docker Image to Artifact Registry](#pushing-drugflow-image-to-gcp-artifact-registry)  \n",
    "- [Building & Running the Container Locally](#building-and-running-the-docker-container)  \n",
    "- [Submitting a Vertexâ€¯AI Custom Job](#submit-custom-job-to-vertex-ai)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Make sure you have:\n",
    "\n",
    "- [Docker](https://docs.docker.com/get-docker/)  \n",
    "- Google Cloud credentials [configured locally](https://cloud.google.com/docs/authentication#set_up)  \n",
    "- A user with the `Vertex AI User` role in your project  \n",
    "- NVIDIA Container Toolkit (if using GPU)  \n",
    "- (Optional) [VS Code](https://code.visualstudio.com/) with Remote â€‘ Containers\n",
    "\n",
    "See [local-env.md](./local-env.md) for more setup tips.\n",
    "\n",
    "---\n",
    "\n",
    "## Pushing DrugFlow Image to GCP Artifact Registry\n",
    "\n",
    "1. **Clone the repository**\n",
    "\n",
    "    ```bash\n",
    "    git clone https://github.com/gabenavarro/MLContainerLab.git\n",
    "    cd MLContainerLab\n",
    "    ```\n",
    "\n",
    "2. **Build the Docker image**\n",
    "\n",
    "    ```bash\n",
    "    docker build -f ./assets/build/Dockerfile.drugflow.cu121cp311 \\\n",
    "      -t drugflow:121-311 .\n",
    "    ```\n",
    "    > On macOS with M1/M2 chip, add `--platform linux/amd64`.\n",
    "\n",
    "3. **Tag the image for GCP Artifact Registry**\n",
    "\n",
    "    ```bash\n",
    "    docker tag drugflow:121-311 \\\n",
    "      ${DEFAULT_ARTIFACT_REGISTRY}/${PROJECT_ID}/${REPO}/drugflow:121-311\n",
    "    ```\n",
    "\n",
    "4. **Push to Artifact Registry**\n",
    "\n",
    "    ```bash\n",
    "    docker push ${DEFAULT_ARTIFACT_REGISTRY}/${PROJECT_ID}/${REPO}/drugflow:121-311\n",
    "    ```\n",
    "\n",
    "> Ensure your Docker has credentials to push to Registryâ€”see [local-env.md](./local-env.md).\n",
    "\n",
    "---\n",
    "\n",
    "## Building & Running the Docker Container Locally\n",
    "\n",
    "1. **Clone the repo** (if not already done)\n",
    "\n",
    "    ```bash\n",
    "    git clone https://github.com/gabenavarro/MLContainerLab.git && cd MLContainerLab\n",
    "    ```\n",
    "\n",
    "2. **Build the GCP Vertex AI image**\n",
    "\n",
    "    ```bash\n",
    "    docker build -f ./assets/build/Dockerfile.gcpvertexiai.cp312 \\\n",
    "      -t vertexai:312 .\n",
    "    ```\n",
    "\n",
    "3. **Run the container interactively**\n",
    "\n",
    "    ```bash\n",
    "    docker run -dt \\\n",
    "      --gpus all \\\n",
    "      -v \"$(pwd):/workspace\" \\\n",
    "      --name vertexai \\\n",
    "      vertexai:312\n",
    "    ```\n",
    "\n",
    "4. **(Optional) Attach VS Code**\n",
    "\n",
    "    ```bash\n",
    "    CONTAINER=vertexai; FOLDER=/workspace\n",
    "    HEX=$(printf \"{\\\"containerName\\\":\\\"/$CONTAINER\\\"}\" | od -A n -t x1 | tr -d ' \\n')\n",
    "    code --folder-uri \"vscode-remote://attached-container+$HEX$FOLDER\"\n",
    "    ```\n",
    "\n",
    "> The `-v` flag mounts your code inside the container, and GPU and GCP credentials are available within it.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Submitting Job to Vertex AI\n",
    "\n",
    "Now, lets go through an example of submitting the Docker container as a managed job.\n",
    "\n",
    "\n",
    "1. **Authentication**\n",
    "\n",
    "First, start by authenticating  your session using user credentials in bash. If you are using a containerized notebook using vscode, make sure to open the terminal in the container and run the following command there.\n",
    "\n",
    "```bash\n",
    "# Authenticate credentials\n",
    "gcloud auth login\n",
    "# Setup configuration\n",
    "# Most likely you will want to use option 1 when prompted\n",
    "gcloud init \n",
    "# Lastly setup ADC authetication\n",
    "gcloud auth application-default login \n",
    "```\n",
    "\n",
    "2.  **Build Files**\n",
    "\n",
    "First, initialize function below in order to read in file with molecules that you'd like to bind to an input protein of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify to fit your project\n",
    "PROJECT = \"YOUR-PROJECT-NAME\"\n",
    "REGION = \"YOUR-REGION\"\n",
    "ARTIFACT_PROJECT = \"ARTIFACT-REGISTRY-PROJECT\"\n",
    "REGISTRY_REGION = \"YOUR-ARTIFACT-REGION\"\n",
    "BUCKET = \"YOUR-BUCKET-NAME\"\n",
    "MACHINE_TYPE = \"\"\n",
    "ACCELERATOR_TYPE = \"\"\n",
    "IMAGE = f\"{REGISTRY_REGION}/{PROJECT}/${ARTIFACT_PROJECT}/drugflow:121-311\"\n",
    "FLEX_START_MACHINES = []\n",
    "VALID_AMINO_ACIDS = set(\"ACDEFGHIKLMNPQRSTVWY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95104696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from networkx import project\n",
    "from pandas import read_csv\n",
    "from rdkit import Chem\n",
    "from datetime import datetime\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform_v1.types import custom_job as gca_custom_job_compat\n",
    "import subprocess\n",
    "import hashlib\n",
    "from time import sleep\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "def check_gcs_file_exists(bucket_name:str, blob_name:str):\n",
    "    \"\"\"Checks if a file exists in a GCS bucket.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the GCS bucket.\n",
    "        file_name (str): The name of the file (object) within the bucket.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file exists, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob_exists = blob.exists()\n",
    "    except:\n",
    "        blob_exists = False\n",
    "    finally:\n",
    "        storage_client.close()\n",
    "    \n",
    "    return blob_exists\n",
    "\n",
    "\n",
    "def build_drugflow_jobs(\n",
    "    pdb_file: str,\n",
    "    sdf_file: str,\n",
    "    experiment_name: str | None = None,\n",
    "    samples: int = 1000,\n",
    "    steps: List[int] | None = None,\n",
    "):\n",
    "    \n",
    "    experiment_name = experiment_name if experiment_name is not None else datetime.today().strftime(\"%d-%m-%Y--%H-%M-%S\")\n",
    "\n",
    "    # Get position of pdb and sdf files in GCP\n",
    "    gcs_pdb = f\"/gcs/{BUCKET}/drugflow/jobs/{experiment_name}/{pdb_file.split('/',-1)}\"\n",
    "    gcs_sdf = f\"/gcs/{BUCKET}/drugflow/jobs/{experiment_name}/{sdf_file.split('/',-1)}\"\n",
    "\n",
    "    # Move them to GCP, will only work if authenticated\n",
    "    cmd = f\"gsutil cp {pdb_file} gs://{BUCKET}/drugflow/jobs/{experiment_name}\"\n",
    "    subprocess.run(cmd,shell=True)\n",
    "    cmd = f\"gsutil cp {gcs_sdf} gs://{BUCKET}/drugflow/jobs/{experiment_name}\"\n",
    "    subprocess.run(cmd,shell=True)\n",
    "\n",
    "    # Get AA seq for hash\n",
    "    pdb_seq = None\n",
    "    try:\n",
    "        pdb = [i.seq for i in SeqIO.parse(pdb_file, \"pdb-seqres\") if len(i.seq)>3 and not (set(i.seq) - VALID_AMINO_ACIDS)]\n",
    "        assert len(pdb) == 1, f\"Provided pdb file {pdb_file} does not have a single sequence, please review\"\n",
    "        pdb_seq = str(pdb[0])\n",
    "    except:\n",
    "        print(f\"Problem reading pdb file: {pdb_file}\")\n",
    "    \n",
    "    # Get mol smiles for hash\n",
    "    mol_smiles = None\n",
    "    try:\n",
    "        mol = Chem.MolFromFile(sdf_file)\n",
    "        mol_smiles = str(Chem.MolToSmiles(mol))\n",
    "    except:\n",
    "        print(f\"Problem reading sdf file: {sdf_file}\")\n",
    "    \n",
    "    # Make provided files meet minimum specification\n",
    "    assert mol_smiles is not None and pdb_seq is not None, \"Provided files are not acceptable\"\n",
    "\n",
    "    # Create jobs based on diffusion steps\n",
    "    if steps is None:\n",
    "        steps = [5,10,20,40,80]\n",
    "\n",
    "    jobs = []\n",
    "    for step in steps:\n",
    "        jobs.append(\n",
    "            {\n",
    "                \"hash_name\": hashlib.sha256(str(pdb_seq.upper()+mol_smiles.upper()).encode('utf-8')).hexdigest(),\n",
    "                \"pdb_file\": gcs_pdb,\n",
    "                \"sdf_file\": gcs_sdf,\n",
    "                \"experiment_name\": experiment_name,\n",
    "                \"n_steps\": step,\n",
    "                \"n_samples\": samples,\n",
    "                \n",
    "            }\n",
    "        )\n",
    "\n",
    "    return jobs\n",
    "\n",
    "\n",
    "def submit_vertex_custom_job(yaml_jobs: List[Dict[str,str]]):\n",
    "\n",
    "    aiplatform.init(\n",
    "        project=PROJECT,\n",
    "        location=REGION\n",
    "    )\n",
    "\n",
    "    for job in yaml_jobs:\n",
    "        pdb_file = job.get(\"pdb_file\", None)\n",
    "        sdf_file = job.get(\"sdf_file\", None)\n",
    "        experiment_name = job.get(\"experiment_name\", None)\n",
    "        n_steps = job.get(\"n_steps\", 10)\n",
    "        n_samples = job.get(\"n_samples\", 1000)\n",
    "        hash_name = job.get(\"hash_name\", None)\n",
    "\n",
    "        if check_gcs_file_exists(\n",
    "            BUCKET,\n",
    "            f\"/drugflow/results/{experiment_name}/drugflow_samples.sdf\"\n",
    "        ):\n",
    "            continue\n",
    "    \n",
    "        CMD = [\n",
    "            \"python\", \"/workspace/src/generate.py\",\n",
    "            \"--protein\", f\"{pdb_file}\",\n",
    "            \"--ref_ligand\", f\"{sdf_file}\",\n",
    "            \"--checkpoint\", \"/models/drugflow/drugflow.ckpt\",\n",
    "            \"--output\", f\"/gcs/{BUCKET}/drugflow/results/{experiment_name}/{hash_name}-{n_steps}steps-{n_samples}samples.sdf\",\n",
    "            \"--metrics_output\", f\"/gcs/{BUCKET}/drugflow/results/{experiment_name}/{hash_name}-{n_steps}steps-{n_samples}samples-metrics.csv\",\n",
    "            \"--n_steps\", f\"{n_steps}\",\n",
    "            \"--n_samples\", f\"{n_samples}\",\n",
    "            \"--reduce\", \"/miniconda/envs/drugflow/bin/reduce\"\n",
    "        ]\n",
    "\n",
    "        WORKER_POOL_SPECS = [\n",
    "            {\n",
    "                \"replica_count\": 1,\n",
    "                \"machine_spec\": {\n",
    "                    \"machine_type\": MACHINE_TYPE,\n",
    "                    \"accelerator_count\": 1,\n",
    "                    \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "                },\n",
    "                \"container_spec\": {\n",
    "                    \"image_uri\": IMAGE, \n",
    "                    \"command\": CMD, \n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        job = aiplatform.CustomJob(\n",
    "            display_name=f\"Boltz-2 {experiment_name}\", \n",
    "            worker_pool_specs=WORKER_POOL_SPECS,\n",
    "            staging_bucket=f\"gs://{BUCKET}/vertex_staging\",\n",
    "        )\n",
    "\n",
    "        if MACHINE_TYPE in FLEX_START_MACHINES:\n",
    "            job.submit(\n",
    "                max_wait_duration=7200,\n",
    "                scheduling_strategy=gca_custom_job_compat.Scheduling.Strategy.FLEX_START\n",
    "            )\n",
    "        else:\n",
    "            job.submit()\n",
    "\n",
    "        sleep(5)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9dbae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_jobs = build_drugflow_jobs(\n",
    "    \"\",\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "submit_vertex_custom_job(vertex_jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
