{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9900fd",
   "metadata": {},
   "source": [
    "# Flash Attention with Docker for Local Development and Scaling\n",
    "\n",
    "This document provides a guide on how to set up Flash Attention using Docker for local development and scaling. It includes instructions for building the Docker image, running the container, and using Flash Attention in your projects.\n",
    "\n",
    "## Prerequisites\n",
    "- Docker installed on your machine\n",
    "- A compatible GPU (NVIDIA) \n",
    "- NVIDIA Docker runtime installed\n",
    "\n",
    "## Sections\n",
    "- [Building the Docker Image](#building-the-docker-image)\n",
    "- [Using Flash Attention Locally](#using-flash-attention)\n",
    "- [Scaling with GCP Cloud Computing](#scaling-with-gcp-cloud-computing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000cc18d",
   "metadata": {},
   "source": [
    "## Building the Docker Image\n",
    "\n",
    "To build the Docker image for Flash Attention, follow these steps.\n",
    "\n",
    "1. Clone the repository:\n",
    "   ```bash\n",
    "   git clone https://github.com/gabenavarro/MLContainerLab.git\n",
    "   cd MLContainerLab\n",
    "   ```\n",
    "2. Build the Docker image:\n",
    "   ```bashll\n",
    "   docker build -f ./assets/build/Dockerfile.flashattn.cu128py26cp312 -t flash-attention:128-26-312 .\n",
    "   ```\n",
    "\n",
    "   > Note: The following steps are to development within the container. My tutorials will be run inside the container, so you can skip them if you are not interested in development.\n",
    "\n",
    "3. Run the Docker container detached with terminal access and GPUs connected:\n",
    "   ```bash\n",
    "   docker run -dt \\\n",
    "   --gpus all \\\n",
    "   -v \"$(pwd):/workspace\" \\\n",
    "   --name flash-attention \\\n",
    "   --env NVIDIA_VISIBLE_DEVICES=all \\\n",
    "   --env GOOGLE_APPLICATION_CREDENTIALS=/workspace/assets/secrets/gcp-key.json \\\n",
    "   flash-attention:128-26-312\n",
    "   ```\n",
    "   > Note: The `-v $(pwd):/workspace` option mounts the current directory to `/workspace` in the container, allowing you to access your files from within the container. <br>\n",
    "   > Note: The `--env` options set environment variables for GPU visibility and Google Cloud credentials. <br>\n",
    "   > Note: The `--gpus all` option allows the container to use all available GPUs. <br>\n",
    "   > Note: The `--name` option names the container `flash-attention`, which you can use to reference it later. <br>\n",
    "   > Note: The `-dt` option runs the container in detached mode with terminal access. <br>\n",
    "   > Note: Get your token from [Synapse](https://synapse.org/), and set it as an environment variable in the container. You can also set it in your local environment, but this is not recommended for security reasons. <br>\n",
    "   > Note: Get a GCP key from [Google Cloud](https://cloud.google.com/docs/authentication/getting-started) and set it as an environment variable in the container. You can also set it in your local environment, but this is not recommended for security reasons. <br>\n",
    "\n",
    "4. Open the container in VSCode: \n",
    "   ```bash\n",
    "   code --folder-uri vscode-remote://dev-container+flash-attention/workspace\n",
    "   ```\n",
    "\n",
    "   If you have the Remote - Containers extension installed, this command will open the current directory in VSCode, allowing you to edit files directly in the container.\n",
    "   If this fails, you can use the GUI to open the container:\n",
    "   - Open VSCode\n",
    "   - Press `F1` and type `Remote-Containers: Attach to Running Container...`\n",
    "   - Select the `flash-attention` container from the list\n",
    "   - This will open the container in a new VSCode window\n",
    "   - Set workspace to `/workspace` in the container\n",
    "\n",
    "   > Note: This command opens the current directory in VSCode, allowing you to edit files directly in the container. <br>\n",
    "   > Note: You may need to install the Remote - Containers extension in VSCode to use this feature. <br>\n",
    "   > Note: You may need to install the Python extension in VSCode to use this feature. <br>\n",
    "   > Note: You may need to install the Jupyter extension in VSCode to use this feature. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639cb32f",
   "metadata": {},
   "source": [
    "## Using Flash Attention\n",
    "\n",
    "### Dataset Preparation\n",
    "Lets setup a simple example to run Flash Attention in the container. First lets start off by downloading a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451256c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_SERIES_CSV = \"/workspace/datasets/btcusd_1-min_data.csv\"\n",
    "PROCESSED_DATA_DIR = \"/workspace/datasets/auto_regressive_processed_timeseries\"\n",
    "CKPT_DIR = \"/workspace/datasets/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6838fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories if they do not exist\n",
    "import os\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Download and unzip the Bitcoin historical data dataset from Kaggle\n",
    "!curl -L -o /workspace/datasets/bitcoin-historical-data.zip \\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/mczielinski/bitcoin-historical-data \\\n",
    "    && unzip -o /workspace/datasets/bitcoin-historical-data.zip -d /workspace/datasets/ \\\n",
    "    && rm /workspace/datasets/bitcoin-historical-data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e083ecb",
   "metadata": {},
   "source": [
    "After downloading the dataset, we can load it into a Pandas DataFrame and take a look at the first few rows. The dataset contains historical data for Bitcoin, including the date, open, high, low, close prices, and volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10c59d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.325412e+09</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-01 10:01:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.325412e+09</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-01 10:02:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.325412e+09</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-01 10:03:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.325412e+09</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-01 10:04:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.325412e+09</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-01 10:05:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp  Open  High   Low  Close  Volume                   datetime\n",
       "0  1.325412e+09  4.58  4.58  4.58   4.58     0.0  2012-01-01 10:01:00+00:00\n",
       "1  1.325412e+09  4.58  4.58  4.58   4.58     0.0  2012-01-01 10:02:00+00:00\n",
       "2  1.325412e+09  4.58  4.58  4.58   4.58     0.0  2012-01-01 10:03:00+00:00\n",
       "3  1.325412e+09  4.58  4.58  4.58   4.58     0.0  2012-01-01 10:04:00+00:00\n",
       "4  1.325412e+09  4.58  4.58  4.58   4.58     0.0  2012-01-01 10:05:00+00:00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.read_csv(TIME_SERIES_CSV, low_memory=False, nrows=5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35edf2b",
   "metadata": {},
   "source": [
    "Now that we have the dataset, lets create a dataset and dataloader for the model using litdata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ccd518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an account on https://lightning.ai/ to optimize your data faster using multiple nodes and large machines.\n",
      "Setting multiprocessing start_method to fork. Tip: Libraries relying on lock can hang with `fork`. To use `spawn` in notebooks, move your code to files and import it within the notebook.\n",
      "Storing the files under /workspace/datasets/auto_regressive_processed_timeseries\n",
      "Setup started with fast_dev_run=False.\n",
      "Setup finished in 0.001 seconds. Found 13690 items to process.\n",
      "Starting 4 workers with 13690 items. The progress bar is only updated when a worker finishes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3577: UserWarning: A newer version of litdata is available (0.2.46). Please consider upgrading with `pip install -U litdata`. Not all functionalities of the platform can be guaranteed to work with the current version.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 inferred the following `['int', 'numpy', 'no_header_numpy:13', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float']` data format.Rank 1 inferred the following `['int', 'numpy', 'no_header_numpy:13', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float']` data format.\n",
      "Workers are ready ! Starting data processing...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e499d099eb62425883ddc2804890e1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/13690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2 inferred the following `['int', 'numpy', 'no_header_numpy:13', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float']` data format.\n",
      "Rank 3 inferred the following `['int', 'numpy', 'no_header_numpy:13', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float']` data format.\n",
      "Worker 1 is terminating.\n",
      "Worker 1 is done.\n",
      "Worker 2 is terminating.\n",
      "Worker 0 is terminating.\n",
      "Worker 3 is terminating.\n",
      "Worker 2 is done.\n",
      "Worker 0 is done.Worker 3 is done.\n",
      "\n",
      "Workers are finished.\n",
      "Finished data processing!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import litdata as ld\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "import torch\n",
    "\n",
    "def process_timeseries(file_path: str, sequence_length: int = 2048) -> Dict[str, Any]:\n",
    "    \"\"\"Process a timeseries CSV file into a format suitable for autoregressive modeling with mask\"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    \n",
    "    # Drop datetime\n",
    "    if \"datetime\" in df.columns:\n",
    "        df = df.drop(columns=[\"datetime\"])\n",
    "    \n",
    "    # Sort by timestamp to ensure chronological order\n",
    "    df = df.sort_values('Timestamp')\n",
    "    \n",
    "    # Select the numerical columns for prediction\n",
    "    numerical_features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    \n",
    "    # Normalize the data to prevent numerical instability - NEW!\n",
    "    # Store statistics for later use\n",
    "    stats = {}\n",
    "    for feature in numerical_features:\n",
    "        # Replace infinity values with NaN\n",
    "        df[feature] = df[feature].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Calculate statistics using only finite values\n",
    "        finite_values = df[feature].dropna()\n",
    "        if len(finite_values) > 0:\n",
    "            mean = finite_values.mean()\n",
    "            std = finite_values.std()\n",
    "            # Prevent zero std which would cause division by zero\n",
    "            if std == 0:\n",
    "                std = 1.0\n",
    "            \n",
    "            # Store stats for this feature\n",
    "            stats[feature] = {'mean': mean, 'std': std}\n",
    "            \n",
    "            # Normalize the feature\n",
    "            df[feature] = (df[feature] - mean) / std\n",
    "    \n",
    "    # Check if we have enough data\n",
    "    if len(df) <= sequence_length:\n",
    "        print(f\"Warning: File {file_path} has {len(df)} rows, which is less than the required sequence_length {sequence_length}.\")\n",
    "        return None  # Return None for the entire file, not just specific indices\n",
    "    \n",
    "    # Function to create samples for litdata - modified to handle edge cases and NaN values\n",
    "    def create_timeseries_sample(index: int) -> Dict[str, Any]:\n",
    "        # Only process indices that have enough previous data\n",
    "        if index < sequence_length or index >= len(df):\n",
    "            # Create writable arrays\n",
    "            input_array = np.zeros((sequence_length, len(numerical_features)), dtype=np.float32).copy()\n",
    "            mask_array = np.zeros(sequence_length, dtype=np.bool_).copy()  # All positions invalid\n",
    "            \n",
    "            return {\n",
    "                \"index\": index,\n",
    "                \"inputs\": input_array,\n",
    "                \"mask\": mask_array,  # No valid positions\n",
    "                \"stats\": stats       # Include normalization stats\n",
    "            }\n",
    "            \n",
    "        # Get the sequence of previous data points\n",
    "        input_sequence = df.iloc[index-sequence_length:index][numerical_features].values\n",
    "        \n",
    "        # Make a writable copy of the arrays\n",
    "        input_array = input_sequence.astype(np.float32).copy()\n",
    "        \n",
    "        # Additional check to replace any remaining NaN or inf values\n",
    "        input_array = np.nan_to_num(input_array, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        # Create mask based on both sequence positions and NaN values\n",
    "        # True for valid positions (not NaN), False for invalid (NaN)\n",
    "        mask_array = ~np.isnan(input_sequence).any(axis=1)\n",
    "        \n",
    "        # Return the required keys: index, inputs, and mask\n",
    "        return {\n",
    "            \"index\": index,\n",
    "            \"inputs\": input_array,\n",
    "            \"mask\": mask_array,\n",
    "            \"stats\": stats  # Include normalization stats\n",
    "        }\n",
    "    \n",
    "    return create_timeseries_sample\n",
    "\n",
    "\n",
    "# Set the sequence length for your model\n",
    "sequence_length = 2048\n",
    "\n",
    "# Get the processing function configured for your specific file\n",
    "process_function = process_timeseries(TIME_SERIES_CSV, sequence_length)\n",
    "\n",
    "# Filter indices to exclude those with NaN values\n",
    "def get_valid_indices():\n",
    "    df = pd.read_csv(TIME_SERIES_CSV, low_memory=False)\n",
    "    if \"datetime\" in df.columns:\n",
    "        df = df.drop(columns=[\"datetime\"])\n",
    "    \n",
    "    df = df.sort_values('Timestamp')\n",
    "    numerical_features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    \n",
    "    # Replace infinity values with NaN\n",
    "    for feature in numerical_features:\n",
    "        df[feature] = df[feature].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    valid_indices = []\n",
    "    for idx in range(sequence_length, len(df), int(sequence_length * 0.25)):\n",
    "        # Check if the entire sequence has no NaN values\n",
    "        sequence = df.iloc[idx-sequence_length:idx][numerical_features].values\n",
    "        if not np.isnan(sequence).any() and not np.isinf(sequence).any():\n",
    "            valid_indices.append(idx)\n",
    "        else:\n",
    "            print(f\"Skipping index {idx} due to NaN or inf values in the sequence.\")\n",
    "    \n",
    "    if not valid_indices:\n",
    "        raise ValueError(\"No valid sequences found! All sequences contain NaN or inf values.\")\n",
    "    \n",
    "    return valid_indices\n",
    "\n",
    "valid_indices = get_valid_indices()\n",
    "\n",
    "# The optimize function writes data in an optimized format\n",
    "ld.optimize(\n",
    "    fn=process_function,              # the function that processes each sample\n",
    "    inputs=valid_indices,             # the indices of valid samples\n",
    "    output_dir=PROCESSED_DATA_DIR,    # optimized data is stored here\n",
    "    num_workers=4,                    # The number of workers on the same machine\n",
    "    chunk_bytes=\"64MB\"                # size of each chunk\n",
    ")\n",
    "# Takes about 30 seconds to run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621a429",
   "metadata": {},
   "source": [
    "Next, lets split the dataset into training and validation sets. We will use 80% of the data for training and 10% for validation and 10% for test. We will also create a dataloader for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "108fa799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13690\n",
      "Train  10952\n",
      "Validation  1369\n"
     ]
    }
   ],
   "source": [
    "from litdata import StreamingDataset, StreamingDataLoader, train_test_split\n",
    "import torch\n",
    "streaming_dataset = StreamingDataset(PROCESSED_DATA_DIR) # data are stored in the cloud\n",
    "\n",
    "def custom_collate(batch):\n",
    "    # Filter out None values\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    \n",
    "    if not batch:\n",
    "        # Return empty tensors if the batch is empty\n",
    "        return {\n",
    "            \"index\": torch.tensor([], dtype=torch.long),\n",
    "            \"inputs\": torch.tensor([], dtype=torch.float32),\n",
    "            \"mask\": torch.tensor([], dtype=torch.bool),\n",
    "            \"stats\": {}\n",
    "        }\n",
    "    \n",
    "    # Process each key separately\n",
    "    indices = torch.tensor([item[\"index\"] for item in batch], dtype=torch.long)\n",
    "    \n",
    "    # Make sure arrays are writable by copying and convert to tensor\n",
    "    inputs = torch.stack([torch.tensor(np.nan_to_num(item[\"inputs\"].copy(), nan=0.0), dtype=torch.float32) for item in batch])\n",
    "    masks = torch.stack([torch.tensor(item[\"mask\"].copy(), dtype=torch.bool) for item in batch])\n",
    "    \n",
    "    # Get stats (use first non-empty item's stats)\n",
    "    stats = next((item[\"stats\"] for item in batch if \"stats\" in item), {})\n",
    "    \n",
    "    return {\n",
    "        \"index\": indices,\n",
    "        \"inputs\": inputs,\n",
    "        \"mask\": masks,\n",
    "        \"stats\": stats\n",
    "    }\n",
    "\n",
    "print(len(streaming_dataset)) # display the length of your data\n",
    "# out: 100,000\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = train_test_split(streaming_dataset, splits=[0.8, 0.1, 0.1])\n",
    "\n",
    "print(\"Train \", len(train_dataset))\n",
    "train_dataloader = StreamingDataLoader(train_dataset, num_workers=4, batch_size=32, shuffle=True, collate_fn=custom_collate)  # Create DataLoader for training\n",
    "# out: 80,000\n",
    "\n",
    "print(\"Validation \", len(val_dataset))\n",
    "val_dataloader = StreamingDataLoader(val_dataset, num_workers=4, batch_size=32, shuffle=False, collate_fn=custom_collate)  # Create DataLoader for validation\n",
    "\n",
    "test_dataloader = StreamingDataLoader(test_dataset, num_workers=4, batch_size=32, shuffle=False, collate_fn=custom_collate)\n",
    "# out: 10,000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe79c285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2048, 5])\n"
     ]
    }
   ],
   "source": [
    "# Get train_dataset and findout dataset shape for input dimensions\n",
    "for batch in train_dataloader:\n",
    "    print(batch['inputs'].shape)  # Check the shape of the input tensor\n",
    "    # out: torch.Size([32, 2048, 5])\n",
    "    # 32 is the batch size, 2048 is the sequence length, and 5 is the number of features\n",
    "    break  # Only need to check the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03fb99",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "\n",
    "Now that we have the dataset and dataloader, we can define the model. To do this, we will create a class that inherits from `nn.Module` and define the model architecture in the `__init__` method. We will also define the forward pass in the `forward` method.\n",
    "\n",
    "The model architecture consists of an embedding layer, a transformer encoder, and a linear layer. The embedding layer converts the input data into a higher-dimensional space, the transformer encoder processes the data using self-attention mechanisms, and the linear layer outputs the final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c990221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/flash_attn-2.7.4.post1-py3.12-linux-x86_64.egg/flash_attn/ops/fused_dense.py:29: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/usr/local/lib/python3.12/dist-packages/flash_attn-2.7.4.post1-py3.12-linux-x86_64.egg/flash_attn/ops/fused_dense.py:70: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "/usr/local/lib/python3.12/dist-packages/flash_attn-2.7.4.post1-py3.12-linux-x86_64.egg/flash_attn/ops/fused_dense.py:251: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/usr/local/lib/python3.12/dist-packages/flash_attn-2.7.4.post1-py3.12-linux-x86_64.egg/flash_attn/ops/fused_dense.py:348: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n"
     ]
    }
   ],
   "source": [
    "# Transformer Layer\n",
    "from flash_attn.modules.mha import MHA\n",
    "from flash_attn.ops.rms_norm import RMSNorm\n",
    "from flash_attn.ops.fused_dense import FusedMLP\n",
    "from torch import nn, optim, Tensor\n",
    "import lightning as pl\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            layer_idx: int,\n",
    "            embed_dim: int,\n",
    "            num_heads: int,\n",
    "            mlp_ratio: float = 4.0,\n",
    "            proj_groups: int = 1,\n",
    "            droput: float = 0.05,\n",
    "            fast_attention: bool = True,\n",
    "        ):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "\n",
    "        self.attention = MHA(\n",
    "            embed_dim = embed_dim,                   # Dimension of the model\n",
    "            num_heads = num_heads,                   # Number of attention heads\n",
    "            causal = True,                           # Causal attention\n",
    "            layer_idx = layer_idx,                   # Layer index for rotary embedding\n",
    "            num_heads_kv = num_heads // proj_groups, # Number of heads for key/value\n",
    "            rotary_emb_dim = embed_dim // num_heads, # Rotary embedding dimension\n",
    "            use_flash_attn = fast_attention,         # Use flash attention\n",
    "            return_residual = False,                 # Return residual connection\n",
    "            dropout=droput,                          # Dropout rate\n",
    "        )\n",
    "        self.norm1 = RMSNorm(embed_dim)\n",
    "        self.mlp = FusedMLP(embed_dim, int(embed_dim * mlp_ratio))\n",
    "        self.norm2 = RMSNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n",
    "        # Apply pre-normalization for stability\n",
    "        normed_x = self.norm1(x)\n",
    "        attn_output = self.attention(normed_x)\n",
    "        x = x + attn_output\n",
    "        \n",
    "        normed_x = self.norm2(x)\n",
    "        mlp_output = self.mlp(normed_x)\n",
    "        x = x + mlp_output\n",
    "        return x\n",
    "\n",
    "    \n",
    "# Transformer Model\n",
    "class AutoregressiveTransformerModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim: int, \n",
    "        embed_dim: int, \n",
    "        num_heads: int, \n",
    "        num_layers: int, \n",
    "        mlp_ratio: float = 4.0,\n",
    "        lr: float = 1e-4,\n",
    "        weight_decay: float = 1e-2,  # Added weight decay\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Linear layer to expand feature size\n",
    "        self.input_proj = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        nn.init.xavier_uniform_(self.input_proj.weight)\n",
    "        nn.init.zeros_(self.input_proj.bias)\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerLayer(layer_idx, embed_dim, num_heads, mlp_ratio) for layer_idx in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final linear layer to project back to input dimension for autoregressive prediction\n",
    "        self.fc_out = nn.Linear(embed_dim, input_dim)\n",
    "        nn.init.xavier_uniform_(self.fc_out.weight)\n",
    "        nn.init.zeros_(self.fc_out.bias)\n",
    "        \n",
    "        # For tracking metrics\n",
    "        self.train_loss = 0.0\n",
    "        self.val_loss = 0.0\n",
    "        \n",
    "        # Learning rate\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "    def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass with optional attention mask\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape [batch_size, seq_len, input_dim]\n",
    "            mask: Boolean mask tensor of shape [batch_size, seq_len]\n",
    "            \n",
    "        Returns:\n",
    "            Tensor of shape [batch_size, seq_len, input_dim]\n",
    "        \"\"\"\n",
    "        # Check for NaN in input and replace with zeros\n",
    "        if torch.isnan(x).any():\n",
    "            x = torch.nan_to_num(x, nan=0.0)\n",
    "            \n",
    "        # Project input to embedding dimension\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Apply transformer layers with attention masking\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask=mask)\n",
    "            \n",
    "            # Check for NaN after each layer (in case of instability)\n",
    "            if torch.isnan(x).any():\n",
    "                print(f\"WARNING: NaN detected in transformer layer output\")\n",
    "                x = torch.nan_to_num(x, nan=0.0)\n",
    "            \n",
    "        # Project back to feature dimension \n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _calculate_autoregressive_loss(self, predictions: Tensor, targets: Tensor, mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Calculate autoregressive loss by comparing predictions at each timestep \n",
    "        with the actual next timestep values\n",
    "        \n",
    "        Args:\n",
    "            predictions: Model predictions [batch_size, seq_len, feature_dim]\n",
    "            targets: Target values [batch_size, seq_len, feature_dim]\n",
    "            mask: Boolean mask [batch_size, seq_len]\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Scalar loss value\n",
    "        \"\"\"\n",
    "        # Shift predictions and targets to align for autoregressive loss\n",
    "        # We predict the next timestep based on previous timesteps\n",
    "        pred_shifted = predictions[:, :-1, :]  # Remove last prediction\n",
    "        target_shifted = targets[:, 1:, :]    # Remove first target\n",
    "        mask_shifted = mask[:, 1:]            # Adjust mask accordingly\n",
    "        \n",
    "        # Calculate MSE loss only on masked positions\n",
    "        mse_loss = nn.MSELoss(reduction='none')(pred_shifted, target_shifted)\n",
    "        \n",
    "        # Apply mask to consider only valid positions (reshape mask to match loss dimensions)\n",
    "        mask_expanded = mask_shifted.unsqueeze(-1).expand_as(mse_loss)\n",
    "        masked_loss = mse_loss * mask_expanded\n",
    "        \n",
    "        # Average the loss over the masked positions, with safety check\n",
    "        num_valid = mask_expanded.sum()\n",
    "        \n",
    "        # Prevent division by zero\n",
    "        if num_valid == 0:\n",
    "            return torch.tensor(0.0, device=predictions.device, requires_grad=True)\n",
    "        \n",
    "        # Check for any NaN in the loss\n",
    "        if torch.isnan(masked_loss).any():\n",
    "            print(\"WARNING: NaN in loss calculation!\")\n",
    "            masked_loss = torch.nan_to_num(masked_loss, nan=0.0)\n",
    "        \n",
    "        loss = masked_loss.sum() / max(num_valid, 1)  # Ensure denominator is at least 1\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step for autoregressive prediction\n",
    "        \"\"\"\n",
    "        # Get inputs and mask from batch\n",
    "        inputs = batch['inputs']\n",
    "        mask = batch['mask']\n",
    "        \n",
    "        # Safety check for NaN in inputs\n",
    "        if torch.isnan(inputs).any():\n",
    "            inputs = torch.nan_to_num(inputs, nan=0.0)\n",
    "        \n",
    "        # Forward pass to get predictions\n",
    "        predictions = self(inputs, mask)\n",
    "        \n",
    "        # Calculate autoregressive loss\n",
    "        loss = self._calculate_autoregressive_loss(predictions, inputs, mask)\n",
    "        \n",
    "        # Check for NaN loss and handle it\n",
    "        if torch.isnan(loss).any():\n",
    "            print(\"NaN loss detected in training step!\")\n",
    "            # Return a small constant loss instead\n",
    "            loss = torch.tensor(0.01, device=loss.device, requires_grad=True)\n",
    "        \n",
    "        \n",
    "        # Log the loss for monitoring\n",
    "        self.train_loss = loss\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step for autoregressive prediction\n",
    "        \"\"\"\n",
    "        # Get inputs and mask from batch\n",
    "        inputs = batch['inputs']\n",
    "        mask = batch['mask']\n",
    "        \n",
    "        # Safety check for NaN in inputs\n",
    "        if torch.isnan(inputs).any():\n",
    "            inputs = torch.nan_to_num(inputs, nan=0.0)\n",
    "        \n",
    "        # Forward pass to get predictions\n",
    "        predictions = self(inputs, mask)\n",
    "        \n",
    "        # Calculate autoregressive loss\n",
    "        loss = self._calculate_autoregressive_loss(predictions, inputs, mask)\n",
    "        \n",
    "        # Check for NaN loss and handle it\n",
    "        if torch.isnan(loss).any():\n",
    "            print(\"NaN loss detected in validation step!\")\n",
    "            # Return a small constant loss instead\n",
    "            loss = torch.tensor(0.01, device=loss.device, requires_grad=True)\n",
    "        \n",
    "        # Log the loss for monitoring\n",
    "        self.val_loss = loss\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Configuring the optimizer\n",
    "    def configure_optimizers(self):\n",
    "        # Use a smaller learning rate and add weight decay\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(), \n",
    "            lr=self.lr, \n",
    "            weight_decay=self.weight_decay,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8          # Increased epsilon for numerical stability\n",
    "        )\n",
    "        \n",
    "        # Add a learning rate scheduler for better convergence\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, \n",
    "            T_max=10,          # Match with max_epochs \n",
    "            eta_min=self.lr\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb87e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /workspace/datasets/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | input_proj | Linear     | 768    | train\n",
      "1 | layers     | ModuleList | 1.2 M  | train\n",
      "2 | fc_out     | Linear     | 645    | train\n",
      "--------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.758     Total estimated model params size (MB)\n",
      "87        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ffefc8784045fcb2c046018e186dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/data.py:123: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c3f44b060d4a6bb3cd0967dbc1cc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize the model\n",
    "parameters = dict(\n",
    "    input_dim = 5,\n",
    "    embed_dim = 128,\n",
    "    num_heads = 8,\n",
    "    num_layers = 6,\n",
    "    lr = 5e-5,            # Reduced learning rate\n",
    "    weight_decay = 1e-2   # Added weight decay\n",
    ")\n",
    "\n",
    "model = AutoregressiveTransformerModel(**parameters)\n",
    "\n",
    "# Lightning callbacks for early stopping and model checkpointing\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath=CKPT_DIR,\n",
    "    filename='best-model-{epoch:02d}-{val_loss:.4f}',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    limit_val_batches=200,\n",
    "    max_epochs=10,\n",
    "    accumulate_grad_batches=16,  \n",
    "    gradient_clip_val=0.25,  # Updated for better stability \n",
    "    default_root_dir=CKPT_DIR,\n",
    "    precision=\"bf16-mixed\",  # Use mixed precision\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback]\n",
    ") \n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ada22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc89ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
